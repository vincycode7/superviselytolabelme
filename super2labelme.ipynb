{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"super2labelme.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1St0WIPif9ByTaaXuL4oz1Hl2wC1qxBQG","authorship_tag":"ABX9TyP54X9AnmyKaYVBM2c2NaJd"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"C35D0DHJzT5n","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"6e623485-a969-4575-865f-2cf5401126d8","executionInfo":{"status":"ok","timestamp":1591488535129,"user_tz":-60,"elapsed":1532,"user":{"displayName":"Akinwande Gbenga Vincent","photoUrl":"","userId":"16034791968116067724"}}},"source":["#Link to my google driveby and change directory to current directory\n","from google.colab import drive   \n","drive.mount('/content/drive')\n","\n","import os\n","os.chdir('/content/drive/My Drive/machine learning/object detection/Testing Platform/Json files')\n"],"execution_count":90,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oHVTgNWnz206","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"318e1b7d-a779-498a-a684-75ad4114e937","executionInfo":{"status":"ok","timestamp":1591492631761,"user_tz":-60,"elapsed":1397,"user":{"displayName":"Akinwande Gbenga Vincent","photoUrl":"","userId":"16034791968116067724"}}},"source":["%%writefile super_to_labelme.py\n","\n","import json\n","import argparse\n","\n","#TODO: Add multi file processing (This solution only works for one json file).\n","\n","class LabelmeDset:\n","  def __init__(self, input_files=[]):\n","    \"\"\"\n","      This Object is used to convert one or more supervisly files\n","      into labelme format.\n","\n","      params: \n","\n","      arg1(input_files) : This is a list of one or more json files\n","      you want to convert to labelme format.\n","\n","      example:\n","            dset = LabelmeDset(input_files=['rset.json','keset.json'])\n","            dset(out_file='trainset.json')\n","    \"\"\"\n","\n","    if type(input_files) != list:\n","      raise Exception('input error, input is expected to be a list of file name(s)')\n","    self.input_files = input_files\n","    self.out_values = {\n","                        'images': [],\n","                        'annotations' : [],\n","                        'categories' : []\n","                      \n","                      }\n","    self.image_id = 0\n","    self.categories_id = 0\n","    self.labels_id = 0\n","\n","  def __call__(self,more_input=None,out_file='output.json'):\n","    \"\"\"\n","      This function is called to run the convertion process, \n","\n","      arg1(more_input) : This is a list of one or more json files\n","      you want to add to the previous list of files to be converted\n","      to labelme format.\n","\n","      arg2(out_file) : This function expects an argument that specifies \n","      the output of the resultant file.\n","      \n","      example1:\n","            dset = LabelmeDset(input_files=['rset.json','keset.json'])\n","            dset(more_input=['jjset.json'],out_file='trainset.json')\n","\n","      example2:\n","            dset = LabelmeDset(input_files=['rset.json','keset.json'])\n","            dset(more_input=None,out_file='trainset.json')\n","\n","      example1:\n","            dset = LabelmeDset(input_files=['rset.json','keset.json'])\n","            dset(out_file='trainset.json')\n","    \"\"\"\n","    self.input_files = self.input_files+more_input if type(more_input) == list else self.input_files\n","    self.process_all_inputs(output=out_file)\n","\n","  def process_all_inputs(self,output=None):\n","    for each_file in self.input_files:\n","      file = open(each_file.strip())\n","      file = json.load(file)\n","\n","      self.out_values['images'] += self.process_image(file['images'])\n","      self.out_values['categories'] += self.process_cat(file['categories'])\n","      self.out_values['annotations'] += self.process_ann(file['annotations'])\n","    \n","    self.save_outfile(output)\n","\n","  def process_image(self,obj_lst=None):\n","    new_lst = []\n","    interested_in = [\"height\", \"width\", \"id\", \"file_name\"]\n","    for each in obj_lst:\n","      new_dict = {}\n","      \n","      for key,value in each.items():\n","          if  key in interested_in and key == 'file_name':\n","            new_dict[key] = value.split('/')[-1]\n","          elif key in interested_in:\n","            new_dict[key] = value\n","      new_lst.append(new_dict)\n","    return new_lst\n","\n","  def process_ann(self,obj_lst=None):\n","    new_lst = []\n","    interested_in = [\"segmentation\", \"iscrowd\", \"area\", \"image_id\",\"bbox\",\"category_id\",\"id\"]\n","    for each in obj_lst:\n","      new_dict = {}\n","      \n","      for key,value in each.items():\n","          if  key in interested_in and key == 'segmentation':\n","            value = value[0]\n","            new_seg = []\n","            for each_seg1,each_seg2 in value:\n","              new_seg.append(each_seg1)\n","              new_seg.append(each_seg2)\n","            new_dict[key] = [new_seg]\n","          elif key in interested_in:\n","            new_dict[key] = value\n","      new_lst.append(new_dict)\n","    return new_lst\n","\n","  def process_cat(self,obj_lst=None):\n","    new_lst = []\n","    interested_in = [\"supercategory\", \"id\", \"name\"]\n","    for each in obj_lst:\n","      new_dict = {}\n","      \n","      for key,value in each.items():\n","          if  key in interested_in and key == 'name':\n","            new_dict['name'] = value\n","          elif key in interested_in:\n","            new_dict[key] = value\n","      new_dict[\"supercategory\"] = new_dict['name']\n","      new_lst.append(new_dict)\n","    return new_lst\n","\n","  def save_outfile(self,output_name='output,json'):\n","    with open(output_name, 'w') as json_file:\n","      json.dump(self.out_values,json_file, indent=4, separators=(',', ': '))\n","\n","def main(args):\n","  dset = LabelmeDset(input_files=args.input_file.split(','))\n","  dset(out_file=args.output_name)\n","\n","if __name__ == '__main__':\n","    parser=argparse.ArgumentParser()\n","    parser.add_argument('--input_file', required=True)\n","    parser.add_argument('--output_name', required=True)\n","    \n","    args=parser.parse_args() \n","    main(args)"],"execution_count":140,"outputs":[{"output_type":"stream","text":["Overwriting super_to_labelme.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hToqpDrK1DZ2","colab_type":"code","colab":{}},"source":["!python3 super_to_labelme.py --input_file train7.json --output_name new_train7.json"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r391x9_ETb2x","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":145},"outputId":"70c5493e-e638-44af-e010-2bca469777ab","executionInfo":{"status":"ok","timestamp":1591491909648,"user_tz":-60,"elapsed":31487,"user":{"displayName":"Akinwande Gbenga Vincent","photoUrl":"","userId":"16034791968116067724"}}},"source":["!python3 super_to_labelme.py --help"],"execution_count":137,"outputs":[{"output_type":"stream","text":["usage: super_to_labelme.py [-h] --input_file INPUT_FILE --output_name\n","                           OUTPUT_NAME\n","\n","optional arguments:\n","  -h, --help            show this help message and exit\n","  --input_file INPUT_FILE\n","  --output_name OUTPUT_NAME\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KFzKrYg_Tdz2","colab_type":"code","colab":{}},"source":["## Test Script\n"],"execution_count":0,"outputs":[]}]}